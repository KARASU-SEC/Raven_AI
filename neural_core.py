"""
–Ø–¥—Ä–æ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ Raven AI (–∏—Å–ø—Ä–∞–≤–ª–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è)
"""
import numpy as np
from typing import List, Dict, Any, Optional
import json
import os
from datetime import datetime
import hashlib

# –ò–°–ü–†–ê–í–õ–ï–ù–û: –£–±–∏—Ä–∞–µ–º –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç—å –æ—Ç torch –µ—Å–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω
try:
    import torch
    import torch.nn as nn
    TORCH_AVAILABLE = True
except ImportError:
    TORCH_AVAILABLE = False
    print("‚ö†Ô∏è PyTorch –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è —É–ø—Ä–æ—â–µ–Ω–Ω—ã–π —Ä–µ–∂–∏–º.")

class NeuralCore:
    """–ù–µ–π—Ä–æ—Å–µ—Ç–µ–≤–æ–µ —è–¥—Ä–æ –¥–ª—è –ø–æ–Ω–∏–º–∞–Ω–∏—è –∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤"""
    
    def __init__(self, model_path: str = "models/neural_core.pt"):
        self.model_path = model_path
        
        # –ö–æ–Ω—Ç–µ–∫—Å—Ç–Ω–∞—è –ø–∞–º—è—Ç—å
        self.context_memory = []
        self.max_context = 10
        
        # –ù–∞–≤—ã–∫–∏
        self.skills = self.load_skills()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏ –µ—Å–ª–∏ torch –¥–æ—Å—Ç—É–ø–µ–Ω
        if TORCH_AVAILABLE:
            self.setup_neural_network()
            self.load_model()
        else:
            print("üß† Neural Core –≤ —É–ø—Ä–æ—â–µ–Ω–Ω–æ–º —Ä–µ–∂–∏–º–µ (–±–µ–∑ PyTorch)")
    
    def setup_neural_network(self):
        """–ù–∞—Å—Ç—Ä–æ–π–∫–∞ –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ (—Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ torch –¥–æ—Å—Ç—É–ø–µ–Ω)"""
        if not TORCH_AVAILABLE:
            return
            
        class SimpleNeuralNetwork(nn.Module):
            def __init__(self):
                super().__init__()
                self.embedding = nn.Embedding(1000, 128)
                self.fc1 = nn.Linear(128, 256)
                self.fc2 = nn.Linear(256, 128)
                self.fc3 = nn.Linear(128, 1000)
                self.dropout = nn.Dropout(0.3)
                self.relu = nn.ReLU()
            
            def forward(self, x):
                embedded = self.embedding(x)
                x = self.relu(self.fc1(embedded.mean(dim=1)))
                x = self.dropout(x)
                x = self.relu(self.fc2(x))
                x = self.dropout(x)
                x = self.fc3(x)
                return x
        
        self.model = SimpleNeuralNetwork()
        self.vocab = {}
        self.inv_vocab = {}
    
    def process_query(self, query: str, context: Optional[List[str]] = None) -> Dict[str, Any]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        # –ê–Ω–∞–ª–∏–∑ –Ω–∞–º–µ—Ä–µ–Ω–∏—è
        intent = self.detect_intent(query)
        
        # –ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π
        entities = self.extract_entities(query)
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–∞
        skill = self.select_skill(intent, entities)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞
        if skill:
            response = self.execute_skill(skill, query, entities)
        else:
            response = self.generate_response(query, context)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        self.update_context(query, response)
        
        # –ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–π
        emotion = self.analyze_emotion(query)
        
        return {
            'query': query,
            'intent': intent,
            'entities': entities,
            'skill': skill,
            'response': response,
            'emotion': emotion,
            'timestamp': datetime.now().isoformat(),
            'context_id': self.generate_context_id(query)
        }
    
    def detect_intent(self, query: str) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞–º–µ—Ä–µ–Ω–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è"""
        query_lower = query.lower()
        
        # –ò–Ω—Ç–µ–Ω—Ç-–¥–µ—Ç–µ–∫—Ü–∏—è
        intents = {
            'greeting': ['–ø—Ä–∏–≤–µ—Ç', '–∑–¥—Ä–∞–≤—Å—Ç–≤—É–π', '–¥–æ–±—Ä—ã–π', '—Ö–∞–π', 'hello', 'hi'],
            'farewell': ['–ø–æ–∫–∞', '–¥–æ —Å–≤–∏–¥–∞–Ω–∏—è', '–ø—Ä–æ—â–∞–π', 'bye', 'goodbye'],
            'question': ['–∫–∞–∫', '–ø–æ—á–µ–º—É', '—á—Ç–æ', '–≥–¥–µ', '–∫–æ–≥–¥–∞', '–∫—Ç–æ', '–∫–∞–∫–æ–π'],
            'command': ['–æ—Ç–∫—Ä–æ–π', '–∑–∞–∫—Ä–æ–π', '–∑–∞–ø—É—Å—Ç–∏', '–≤—ã–∫–ª—é—á–∏', '–ø–æ–∫–∞–∂–∏', '–Ω–∞–π–¥–∏'],
            'system': ['—Å–∏—Å—Ç–µ–º–∞', '–ø—Ä–æ—Ü–µ—Å—Å—ã', '–ø–∞–º—è—Ç—å', 'cpu', 'ram', '–¥–∏—Å–∫'],
            'time': ['–≤—Ä–µ–º—è', '–∫–æ—Ç–æ—Ä—ã–π —á–∞—Å', '–¥–∞—Ç–∞', '—á–∏—Å–ª–æ'],
            'weather': ['–ø–æ–≥–æ–¥–∞', '—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞', '–¥–æ–∂–¥—å', '—Å–æ–ª–Ω—Ü–µ'],
            'entertainment': ['–º—É–∑—ã–∫–∞', '—Ñ–∏–ª—å–º', '–∏–≥—Ä–∞', '—Ä–∞–∑–≤–ª–µ—á–µ–Ω–∏–µ', '—à—É—Ç–∫–∞']
        }
        
        for intent, keywords in intents.items():
            if any(keyword in query_lower for keyword in keywords):
                return intent
        
        return 'unknown'
    
    def extract_entities(self, query: str) -> Dict[str, Any]:
        """–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ —Å—É—â–Ω–æ—Å—Ç–µ–π –∏–∑ –∑–∞–ø—Ä–æ—Å–∞"""
        entities = {
            'applications': [],
            'files': [],
            'urls': [],
            'numbers': [],
            'dates': [],
            'times': [],
            'locations': []
        }
        
        # –ü—Ä–æ—Å—Ç–∞—è —Ä–µ–∞–ª–∏–∑–∞—Ü–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Å—É—â–Ω–æ—Å—Ç–µ–π
        words = query.lower().split()
        
        # –ü—Ä–∏–ª–æ–∂–µ–Ω–∏—è
        apps = ['–±—Ä–∞—É–∑–µ—Ä', 'chrome', 'firefox', 'edge', 'notepad', '–±–ª–æ–∫–Ω–æ—Ç', 
                '–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä', 'word', 'excel', 'steam', 'discord']
        entities['applications'] = [word for word in words if word in apps]
        
        # –ß–∏—Å–ª–∞
        import re
        numbers = re.findall(r'\d+', query)
        entities['numbers'] = [int(num) for num in numbers]
        
        # –í—Ä–µ–º—è
        time_patterns = [r'\d{1,2}:\d{2}', r'\d{1,2} —á–∞—Å–æ–≤', r'\d{1,2} —á–∞—Å']
        for pattern in time_patterns:
            times = re.findall(pattern, query)
            entities['times'].extend(times)
        
        return entities
    
    def select_skill(self, intent: str, entities: Dict) -> Optional[str]:
        """–í—ã–±–æ—Ä –Ω–∞–≤—ã–∫–∞ –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        skill_map = {
            'greeting': 'conversation',
            'farewell': 'conversation',
            'question': 'knowledge',
            'command': 'system_control',
            'system': 'system_monitor',
            'time': 'datetime',
            'weather': 'weather',
            'entertainment': 'entertainment'
        }
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞ —Å–∏—Å—Ç–µ–º–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã
        if entities.get('applications'):
            return 'application_control'
        
        return skill_map.get(intent, 'general')
    
    def execute_skill(self, skill: str, query: str, entities: Dict) -> str:
        """–í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–∞–≤—ã–∫–∞"""
        skill_handlers = {
            'conversation': self.handle_conversation,
            'system_control': self.handle_system_control,
            'system_monitor': self.handle_system_monitor,
            'application_control': self.handle_application_control,
            'datetime': self.handle_datetime,
            'knowledge': self.handle_knowledge,
            'general': self.handle_general
        }
        
        handler = skill_handlers.get(skill, self.handle_general)
        return handler(query, entities)
    
    def handle_conversation(self, query: str, entities: Dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ä–∞–∑–≥–æ–≤–æ—Ä–Ω—ã—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        responses = {
            'greeting': [
                "–ü—Ä–∏–≤–µ—Ç! –†–∞–¥ –≤–∞—Å —Å–ª—ã—à–∞—Ç—å. –ß–µ–º –º–æ–≥—É –ø–æ–º–æ—á—å?",
                "–ó–¥—Ä–∞–≤—Å—Ç–≤—É–π—Ç–µ! Raven AI –∫ –≤–∞—à–∏–º —É—Å–ª—É–≥–∞–º.",
                "–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é! –ì–æ—Ç–æ–≤ –≤—ã–ø–æ–ª–Ω–∏—Ç—å –≤–∞—à–∏ –∫–æ–º–∞–Ω–¥—ã."
            ],
            'farewell': [
                "–î–æ —Å–≤–∏–¥–∞–Ω–∏—è! –ë—É–¥—É –∂–¥–∞—Ç—å –≤–∞—à–µ–≥–æ –≤–æ–∑–≤—Ä–∞—â–µ–Ω–∏—è.",
                "–í—Å–µ–≥–æ —Ö–æ—Ä–æ—à–µ–≥–æ! –ù–µ —Å—Ç–µ—Å–Ω—è–π—Ç–µ—Å—å –æ–±—Ä–∞—â–∞—Ç—å—Å—è.",
                "–ü—Ä–æ—â–∞–π—Ç–µ! –ù–∞–¥–µ—é—Å—å, —è –±—ã–ª –ø–æ–ª–µ–∑–µ–Ω."
            ],
            'thanks': [
                "–í—Å–µ–≥–¥–∞ —Ä–∞–¥ –ø–æ–º–æ—á—å!",
                "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞! –û–±—Ä–∞—â–∞–π—Ç–µ—Å—å –µ—â—ë.",
                "–ù–µ –∑–∞ —á—Ç–æ! –≠—Ç–æ –º–æ—è —Ä–∞–±–æ—Ç–∞."
            ]
        }
        
        import random
        intent = self.detect_intent(query)
        
        if '—Å–ø–∞—Å–∏–±–æ' in query.lower():
            return random.choice(responses['thanks'])
        
        return random.choice(responses.get(intent, ["–Ø –≤–∞—Å —Å–ª—É—à–∞—é."]))
    
    def handle_system_control(self, query: str, entities: Dict) -> str:
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–∏—Å—Ç–µ–º–æ–π"""
        import psutil
        import subprocess
        
        query_lower = query.lower()
        
        if '–æ—Ç–∫—Ä–æ–π' in query_lower or '–∑–∞–ø—É—Å—Ç–∏' in query_lower:
            if entities.get('applications'):
                app = entities['applications'][0]
                try:
                    # –ú–∞–ø–ø–∏–Ω–≥ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
                    app_map = {
                        '–±—Ä–∞—É–∑–µ—Ä': 'chrome.exe',
                        'chrome': 'chrome.exe',
                        '–±–ª–æ–∫–Ω–æ—Ç': 'notepad.exe',
                        'notepad': 'notepad.exe',
                        '–∫–∞–ª—å–∫—É–ª—è—Ç–æ—Ä': 'calc.exe',
                        'calc': 'calc.exe'
                    }
                    
                    app_exe = app_map.get(app, app + '.exe')
                    subprocess.Popen(app_exe, shell=True)
                    return f"‚úÖ –ó–∞–ø—É—Å–∫–∞—é {app}"
                except Exception as e:
                    return f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å {app}: {str(e)}"
        
        elif '–∑–∞–∫—Ä–æ–π' in query_lower:
            # –ó–∞–∫—Ä—ã—Ç–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–π
            for proc in psutil.process_iter(['name']):
                try:
                    if any(app in proc.info['name'].lower() for app in entities.get('applications', [])):
                        proc.terminate()
                        return f"‚úÖ –ó–∞–∫—Ä—ã–ª {proc.info['name']}"
                except:
                    pass
            return "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —É–∫–∞–∑–∞–Ω–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ"
        
        elif '–≤—ã–∫–ª—é—á–∏' in query_lower and ('–∫–æ–º–ø—å—é—Ç–µ—Ä' in query_lower or '–ø–∫' in query_lower):
            return "‚ö†Ô∏è –ö–æ–º–∞–Ω–¥–∞ –≤—ã–∫–ª—é—á–µ–Ω–∏—è –∫–æ–º–ø—å—é—Ç–µ—Ä–∞ —Ç—Ä–µ–±—É–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è"
        
        return "‚ÑπÔ∏è –°–∏—Å—Ç–µ–º–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞"
    
    def handle_system_monitor(self, query: str, entities: Dict) -> str:
        """–ú–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥ —Å–∏—Å—Ç–µ–º—ã"""
        import psutil
        
        cpu = psutil.cpu_percent()
        ram = psutil.virtual_memory().percent
        disk = psutil.disk_usage('C:/').percent if os.name == 'nt' else psutil.disk_usage('/').percent
        
        return f"üìä –°–æ—Å—Ç–æ—è–Ω–∏–µ —Å–∏—Å—Ç–µ–º—ã: CPU {cpu}%, RAM {ram}%, –î–∏—Å–∫ {disk}%"
    
    def handle_application_control(self, query: str, entities: Dict) -> str:
        """–£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è–º–∏"""
        return self.handle_system_control(query, entities)
    
    def handle_datetime(self, query: str, entities: Dict) -> str:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –≤—Ä–µ–º–µ–Ω–∏ –∏ –¥–∞—Ç–µ"""
        from datetime import datetime
        
        now = datetime.now()
        
        if '–≤—Ä–µ–º—è' in query.lower():
            return f"üïí –°–µ–π—á–∞—Å {now.strftime('%H:%M:%S')}"
        elif '–¥–∞—Ç–∞' in query.lower():
            return f"üìÖ –°–µ–≥–æ–¥–Ω—è {now.strftime('%d.%m.%Y')}"
        else:
            return f"üïí {now.strftime('%H:%M:%S')} üìÖ {now.strftime('%d.%m.%Y')}"
    
    def handle_knowledge(self, query: str, entities: Dict) -> str:
        """–û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã"""
        # –ü—Ä–æ—Å—Ç–∞—è –±–∞–∑–∞ –∑–Ω–∞–Ω–∏–π
        knowledge_base = {
            '–∫—Ç–æ —Ç—ã': '–Ø Raven AI, –≤–∞—à –ø–µ—Ä—Å–æ–Ω–∞–ª—å–Ω—ã–π –≥–æ–ª–æ—Å–æ–≤–æ–π –∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.',
            '—á—Ç–æ —Ç—ã —É–º–µ–µ—à—å': '–Ø –º–æ–≥—É —É–ø—Ä–∞–≤–ª—è—Ç—å —Å–∏—Å—Ç–µ–º–æ–π, –æ—Ç–≤–µ—á–∞—Ç—å –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã, –æ—Ç–∫—Ä—ã–≤–∞—Ç—å –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è –∏ –º–Ω–æ–≥–æ–µ –¥—Ä—É–≥–æ–µ.',
            '—Å–æ–∑–¥–∞—Ç–µ–ª—å': '–ú–µ–Ω—è —Å–æ–∑–¥–∞–ª–∏ –∫–∞–∫ –ø—Ä–æ–µ–∫—Ç —Å –æ—Ç–∫—Ä—ã—Ç—ã–º –∏—Å—Ö–æ–¥–Ω—ã–º –∫–æ–¥–æ–º.',
            '–≤–µ—Ä—Å–∏—è': '–¢–µ–∫—É—â–∞—è –≤–µ—Ä—Å–∏—è: Raven AI 2.1 Dashboard Edition'
        }
        
        for pattern, answer in knowledge_base.items():
            if pattern in query.lower():
                return answer
        
        # –ï—Å–ª–∏ –≤–æ–ø—Ä–æ—Å –Ω–µ –Ω–∞–π–¥–µ–Ω
        return "ü§î –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã–π –≤–æ–ø—Ä–æ—Å. –ü–æ–∑–≤–æ–ª—å—Ç–µ –º–Ω–µ –ø–æ–¥—É–º–∞—Ç—å..."
    
    def handle_general(self, query: str, entities: Dict) -> str:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –æ–±—â–∏—Ö –∑–∞–ø—Ä–æ—Å–æ–≤"""
        return "–Ø –ø–æ–Ω—è–ª –≤–∞—à –∑–∞–ø—Ä–æ—Å. –£—Ç–æ—á–Ω–∏—Ç–µ, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞, —á—Ç–æ –∏–º–µ–Ω–Ω–æ –≤—ã —Ö–æ—Ç–∏—Ç–µ —Å–¥–µ–ª–∞—Ç—å?"
    
    def generate_response(self, query: str, context: Optional[List[str]] = None) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞"""
        return self.handle_general(query, {})
    
    def analyze_emotion(self, query: str) -> str:
        """–ê–Ω–∞–ª–∏–∑ —ç–º–æ—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –æ–∫—Ä–∞—Å–∫–∏ –∑–∞–ø—Ä–æ—Å–∞"""
        positive_words = ['—Ö–æ—Ä–æ—à–æ', '–æ—Ç–ª–∏—á–Ω–æ', '—Å–ø–∞—Å–∏–±–æ', '–∫–ª–∞—Å—Å', '—Å—É–ø–µ—Ä', '–ª—é–±–ª—é']
        negative_words = ['–ø–ª–æ—Ö–æ', '—É–∂–∞—Å–Ω–æ', '–Ω–µ–Ω–∞–≤–∏–∂—É', '–±–µ—Å–∏—Ç', '—Ä–∞–∑–¥—Ä–∞–∂–∞–µ—Ç']
        
        query_lower = query.lower()
        
        pos_count = sum(1 for word in positive_words if word in query_lower)
        neg_count = sum(1 for word in negative_words if word in query_lower)
        
        if pos_count > neg_count:
            return 'positive'
        elif neg_count > pos_count:
            return 'negative'
        else:
            return 'neutral'
    
    def update_context(self, query: str, response: str):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω–æ–π –ø–∞–º—è—Ç–∏"""
        self.context_memory.append({
            'query': query,
            'response': response,
            'timestamp': datetime.now().isoformat()
        })
        
        if len(self.context_memory) > self.max_context:
            self.context_memory.pop(0)
    
    def generate_context_id(self, query: str) -> str:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è ID –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        return hashlib.md5(query.encode()).hexdigest()[:8]
    
    def load_skills(self) -> Dict:
        """–ó–∞–≥—Ä—É–∑–∫–∞ –Ω–∞–≤—ã–∫–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
        try:
            skills_path = 'config/skills.json'
            if os.path.exists(skills_path):
                with open(skills_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
        except:
            pass
        return {}
    
    def save_model(self):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏"""
        if TORCH_AVAILABLE:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'vocab': self.vocab,
                'inv_vocab': self.inv_vocab
            }, self.model_path)
    
    def load_model(self):
        """–ó–∞–≥—Ä—É–∑–∫–∞ –º–æ–¥–µ–ª–∏"""
        if not TORCH_AVAILABLE:
            return
            
        try:
            if os.path.exists(self.model_path):
                checkpoint = torch.load(self.model_path)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                self.vocab = checkpoint['vocab']
                self.inv_vocab = checkpoint['inv_vocab']
                print("‚úÖ –ú–æ–¥–µ–ª—å –Ω–µ–π—Ä–æ—Å–µ—Ç–∏ –∑–∞–≥—Ä—É–∂–µ–Ω–∞")
        except Exception as e:
            print(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–≥—Ä—É–∑–∏—Ç—å –º–æ–¥–µ–ª—å: {e}")